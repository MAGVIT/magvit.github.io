<!-- Header -->
<header>
  <div class="container">
    <div class="row">
      <div class="col-lg-12">
        <!-- <img class="img-responsive" src="img/profile.png" alt="profile-pic" /> -->
        <div class="intro-text">
          <span class="name">{{ site.title }}:</span>
          <!-- <hr class="star-light" /> -->
          <span class="skills">{{ site.full_name }}</span>

          <span class="abstract">
            <div class="text-center"><a href="//me.lj-y.com/"><b>Lijun Yu</b><sup>‡†</sup></a>, Yong Cheng<sup>†</sup>, Kihyuk Sohn<sup>†</sup>, José Lezama<sup>†</sup>, Han Zhang<sup>†</sup>, Huiwen Chang<sup>†</sup>,<br>Alexander G. Hauptmann<sup>‡</sup>, Ming-Hsuan Yang<sup>†</sup>, Yuan Hao<sup>†</sup>, Irfan Essa<sup>†+</sup>, <a href="http://www.lujiang.info/"><b>Lu Jiang</b><sup>†</sup></a><br>
            <sup>‡</sup>Carnegie Mellon University, <sup>†</sup>Google Research, <sup>+</sup>Georgia Institute of Technology<br>
            <!-- <a href="mailto:lijun@cmu.edu">lijun@cmu.edu</a>, <a href="mailto:lujiang@google.com">lujiang@google.com</a> -->
            <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yu_MAGVIT_Masked_Generative_Video_Transformer_CVPR_2023_paper.html">CVPR 2023 (Highlight)</a></div> <br>
            We introduce MAGVIT to tackle various video synthesis tasks with a single model, where we demonstrate its quality, efficiency, and flexibility.</span>
        </div>
      </div>
    </div>
  </div>
</header>
